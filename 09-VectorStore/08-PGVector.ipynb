{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25733da0",
   "metadata": {},
   "source": [
    "# PGVector\n",
    "\n",
    "- Author: [Min-su Jung](https://github.com/effort-type), [Joonha Jeon](https://github.com/realjoonha), [Jongho Lee](https://github.com/XaviereKU)\n",
    "- Peer Review : [Joonha Jeon](https://github.com/realjoonha), [Changwon Jeon](https://github.com/changwonjeon), [Sohyeon Yim](https://github.com/sohyunwriter), [BokyungisaGod](https://github.com/BokyungisaGod)\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/09-VectorStore/07-PGVector.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/09-VectorStore/07-PGVector.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial covers how to use **PGVector** with **LangChain** .\n",
    "\n",
    "[**PGVector**](https://github.com/pgvector/pgvector) is an open-source extension for PostgreSQL that allows you to store and search vector data alongside your regular database information.\n",
    "\n",
    "This tutorial walks you through using **CRUD** operations with the **PGVector** **storing** , **updating** , **deleting** documents, and performing **similarity-based retrieval** .\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [What is PGVector?](#what-is-pgvector)\n",
    "- [Prepare Data](#Prepare-Data)\n",
    "- [Setting up PGVector](#Setting-up-PGVector)\n",
    "- [Document Manager](#document-manager)\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "- [langchain-postgres](https://github.com/langchain-ai/langchain-postgres/)\n",
    "- [pgvector](https://github.com/pgvector/pgvector)\n",
    "- [Docker Desktop for Windows](https://docs.docker.com/desktop/setup/install/windows-install)\n",
    "- [Docker Desktop for Mac](https://docs.docker.com/desktop/setup/install/mac-install/)\n",
    "- [Install pgvector on Windows](https://dev.to/mehmetakar/install-pgvector-on-windows-6gl)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fac085",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- ```langchain-opentutorial``` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [```langchain-opentutorial```](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98da7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800c732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_openai\",\n",
    "        \"pgvector\",\n",
    "        \"psycopg\",\n",
    "        \"psycopg-binary\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b36bafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"PGVector\",\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8011a0c7",
   "metadata": {},
   "source": [
    "You can alternatively set API keys such as ```OPENAI_API_KEY``` in a ```.env``` file and load them.\n",
    "\n",
    "[Note] This is not necessary if you've already set the required API keys in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d7e764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6890920d",
   "metadata": {},
   "source": [
    "### Set up PGVector\n",
    "\n",
    "If you are using Windows and have installed postgresql for Windows, you are required to install **vector** extension for postgresql. The following may help [Install pgvector on Windows](https://dev.to/mehmetakar/install-pgvector-on-windows-6gl).\n",
    "\n",
    "But in this tutorial, we will use **Docker** container. If you are using Mac or Windows, check [Docker Desktop for Mac](https://docs.docker.com/desktop/setup/install/mac-install/) or [Docker Desktop for Windows](https://docs.docker.com/desktop/setup/install/windows-install).\n",
    "\n",
    "If you are using **Docker** desktop, you can easily set up **PGVector** by running the following command that spins up a **Docker** container:\n",
    "\n",
    "```bash\n",
    "docker run --name pgvector-container -e POSTGRES_USER=langchain -e POSTGRES_PASSWORD=langchain -e POSTGRES_DB=langchain -p 6088:5432 -d pgvector/pgvector:pg16\n",
    "```\n",
    "\n",
    "For more detailed instructions, please refer to [the official documentation](https://github.com/pgvector/pgvector) \n",
    "\n",
    "**[ NOTE ]**\n",
    "* If you want to maintain the stored data even after container being deleted, you must mount volume like below:\n",
    "```bash\n",
    "docker run --name pgvector-container -v {/mount/path}:/var/lib/postgresql/data -e POSTGRES_USER=langchain -e POSTGRES_PASSWORD=langchain -e POSTGRES_DB=langchain -p 6088:5432 -d pgvector/pgvector:pg16\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc0863",
   "metadata": {},
   "source": [
    "## What is PGVector?\n",
    "\n",
    "**PGVector** is a **PostgreSQL** extension that enables vector similarity search directly within your **PostgreSQL** database, making it ideal for AI applications, semantic search, and recommendation systems.\n",
    "\n",
    "This is particularly valuable for who already use **PostgreSQL** who want to add vector search capabilities without managing separate infrastructure or learning new query languages.\n",
    "\n",
    "**Features** :\n",
    "1. Native **PostgreSQL** integration with standard SQL queries\n",
    "2. Multiple similarity search methods including L2, Inner Product, Cosine\n",
    "3. Several indexing options including HNSW and IVFFlat\n",
    "4. Support for up to 2,000 dimensions per vector\n",
    "5. ACID compliance inherited from **PostgreSQL**\n",
    "\n",
    "**Advantages** :\n",
    "\n",
    "1. Free and open-source\n",
    "2. Easy integration with existing **PostgreSQL** databases\n",
    "3. Full SQL functionality and transactional support\n",
    "4. No additional infrastructure needed\n",
    "5. Supports hybrid searches combining vector and traditional SQL queries\n",
    "\n",
    "**Disadvantages** :\n",
    "1. Performance limitations with very large datasets (billions of vectors)\n",
    "2. Limited to single-node deployment\n",
    "3. Memory-intensive for large vector dimensions\n",
    "4. Requires manual optimization for best performance\n",
    "5. Less specialized features compared to dedicated vector databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3b5bd2",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "This section guides you through the **data preparation process** .\n",
    "\n",
    "This section includes the following components:\n",
    "\n",
    "- Data Introduction\n",
    "\n",
    "- Preprocess Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508ae7f7",
   "metadata": {},
   "source": [
    "### Data Introduction\n",
    "\n",
    "In this tutorial, we will use the fairy tale **ðŸ“— The Little Prince** in PDF format as our data.\n",
    "\n",
    "This material complies with the **Apache 2.0 license** .\n",
    "\n",
    "The data is used in a text (.txt) format converted from the original PDF.\n",
    "\n",
    "You can view the data at the link below.\n",
    "- [Data Link](https://huggingface.co/datasets/sohyunwriter/the_little_prince)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ea4f4",
   "metadata": {},
   "source": [
    "### Preprocess Data\n",
    "\n",
    "In this tutorial section, we will preprocess the text data from The Little Prince and convert it into a list of ```LangChain Document``` objects with metadata. \n",
    "\n",
    "Each document chunk will include a ```title``` field in the metadata, extracted from the first line of each section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4cac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def preprocessing_data(content: str) -> List[Document]:\n",
    "    # 1. Split the text by double newlines to separate sections\n",
    "    blocks = content.split(\"\\n\\n\")\n",
    "\n",
    "    # 2. Initialize the text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,  # Maximum number of characters per chunk\n",
    "        chunk_overlap=50,  # Overlap between chunks to preserve context\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \"],  # Order of priority for splitting\n",
    "    )\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    # 3. Loop through each section\n",
    "    for block in blocks:\n",
    "        lines = block.strip().splitlines()\n",
    "        if not lines:\n",
    "            continue\n",
    "\n",
    "        # Extract title from the first line using square brackets [ ]\n",
    "        first_line = lines[0]\n",
    "        title_match = re.search(r\"\\[(.*?)\\]\", first_line)\n",
    "        title = title_match.group(1).strip() if title_match else None\n",
    "\n",
    "        # Remove the title line from content\n",
    "        body = \"\\n\".join(lines[1:]).strip()\n",
    "        if not body:\n",
    "            continue\n",
    "\n",
    "        # 4. Chunk the section using the text splitter\n",
    "        chunks = text_splitter.split_text(body)\n",
    "\n",
    "        # 5. Create a LangChain Document for each chunk with the same title metadata\n",
    "        for chunk in chunks:\n",
    "            documents.append(Document(page_content=chunk, metadata={\"title\": title}))\n",
    "\n",
    "    print(f\"Generated {len(documents)} chunked documents.\")\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d091a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 262 chunked documents.\n"
     ]
    }
   ],
   "source": [
    "# Load the entire text file\n",
    "with open(\"./data/the_little_prince.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Preprocess Data\n",
    "docs = preprocessing_data(content=content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1977d4ff",
   "metadata": {},
   "source": [
    "## Setting up PGVector\n",
    "\n",
    "This part walks you through the initial setup of **PGVector** .\n",
    "\n",
    "This section includes the following components:\n",
    "\n",
    "- Load Embedding Model\n",
    "\n",
    "- Load PGVector Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee56b2",
   "metadata": {},
   "source": [
    "### Load Embedding Model\n",
    "\n",
    "In this section, you'll learn how to load an embedding model.\n",
    "\n",
    "This tutorial uses **OpenAI's** **API-Key** for loading the model.\n",
    "\n",
    "*ðŸ’¡ If you prefer to use another embedding model, see the instructions below.*\n",
    "- [Embedding Models](https://python.langchain.com/docs/integrations/text_embedding/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bd5c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f65795",
   "metadata": {},
   "source": [
    "### Load PGVector Client\n",
    "\n",
    "In this section, we'll show you how to load the **database client object** using the **Python SDK** for ```PGVector``` .\n",
    "- [PGVector Python SDK Docs](https://github.com/pgvector/pgvector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eed0ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Database Client Object Function\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "def get_db_client(conn_str):\n",
    "    \"\"\"\n",
    "    Initializes and returns a VectorStore client instance.\n",
    "    This function loads configuration (e.g., API key, host) from environment\n",
    "    variables or default values and creates a client object to interact\n",
    "    with the {vectordb} Python SDK.\n",
    "\n",
    "    Returns:\n",
    "        client:ClientType - An instance of the {vectordb} client.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If required configuration is missing.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        client = create_engine(url=conn_str, **({}))\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    else:\n",
    "        return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b5f4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DB Client Object\n",
    "conn_str = \"postgresql+psycopg://langchain:langchain@localhost:6088/langchain\"\n",
    "client = get_db_client(conn_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f4075",
   "metadata": {},
   "source": [
    "If you are successfully running the ```PGVector``` container and get client objecct, you can use ```PGVectorIndexManager``` from ```pgvector.py``` in utils directory to handle collections.\n",
    "\n",
    "You can also initialize ```pGVectorIndexManager``` by passing full connection string or each parameter separately instead of passing client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba8f2308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pgvector import PGVectorIndexManager\n",
    "\n",
    "# Initialize pgVectorIndexManaer\n",
    "index_manager = PGVectorIndexManager(client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734dc3da",
   "metadata": {},
   "source": [
    "When you initialize ```PGVectorIndexManager```, the procedure will automatically create two tables\n",
    "**langchain_pg_collection** and **langchain_pg_embedding.**\n",
    "\n",
    "* langchain_pg_collection\n",
    "    * Stores **names** of the collections.\n",
    "    * Distinguish collection by uuid and name.\n",
    "* langchain_pg_embedding\n",
    "    * Stores actual data.\n",
    "    \n",
    "So, when you create a new collection and insert data to the collection, the data will be stored in **langchain_pg_embedding** table.\n",
    "\n",
    "As you can see below, the uuid column in langchain_pg_collection table matched with collection_id column in langchain_pg_embedding table.\n",
    "\n",
    "![pgVector Entity Relation](./assets/08-pgvector-entityRelation.png)\n",
    "\n",
    "\n",
    "![pgVector Collection](./assets/08-pgvector-collection.png)\n",
    "\n",
    "\n",
    "![pgVector Data](./assets/08-pgvector-data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b661d",
   "metadata": {},
   "source": [
    "### Create collection\n",
    "Now we can create collection with ```index_manager```.\n",
    "\n",
    "To create collection, you need to pass **embedding** model and **collection_name** when calling the ```create_index``` method.\n",
    "\n",
    "In this tutorial we will use ```text-embedding-3-large``` model of OpenAI.\n",
    "\n",
    "If creation is successful, the method will return ```PGVectorDocumentManager``` class that can handle actual data.\n",
    "\n",
    "In this tutorial we will create an collection with name **langchain_opentutorial.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4742c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d92c6846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new collection\n",
    "_ = index_manager.create_index(\n",
    "    collection_name=\"tutorial_collection\", embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a97a0",
   "metadata": {},
   "source": [
    "## Document Manager\n",
    "\n",
    "For the **LangChain-OpenTutorial**, we have implemented a custom set of **CRUD** functionalities for VectorDBs\n",
    "\n",
    "The following operations are included:\n",
    "\n",
    "- ```upsert``` : Update existing documents or insert if they donâ€™t exist\n",
    "\n",
    "- ```upsert_parallel``` : Perform upserts in parallel for large-scale data\n",
    "\n",
    "- ```similarity_search``` : Search for similar documents based on embeddings\n",
    "\n",
    "- ```delete``` : Remove documents based on filter conditions\n",
    "\n",
    "Each of these features is implemented as class methods specific to each VectorDB.\n",
    "\n",
    "In this tutorial, you'll learn how to use these methods to interact with your VectorDB.\n",
    "\n",
    "*We plan to continuously expand the functionality by adding more common operations in the future.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e89549b-fbb4-4a9d-b01d-1898d129b1e2",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "The PGVector support following filtering operations.\n",
    "\n",
    "| Operator | Meaning/Category        |\n",
    "|----------|-------------------------|\n",
    "| \\$eq      | Equality (==)           |\n",
    "| \\$ne      | Inequality (!=)         |\n",
    "| \\$lt      | Less than (&lt;)           |\n",
    "| \\$lte     | Less than or equal (&lt;=) |\n",
    "| \\$gt      | Greater than (>)        |\n",
    "| \\$gte     | Greater than or equal (>=) |\n",
    "| \\$in      | Special Cased (in)      |\n",
    "| \\$nin     | Special Cased (not in)  |\n",
    "| \\$between | Special Cased (between) |\n",
    "| \\$like    | Text (like)             |\n",
    "| \\$ilike   | Text (case-insensitive like) |\n",
    "| \\$and     | Logical (and)           |\n",
    "| \\$or      | Logical (or)            |\n",
    "\n",
    "Filter can be used with ```delete```, and ```search``` methods.\n",
    "\n",
    "To apply filter, we create a dictionary and pass it to ```filter``` parameter like the following\n",
    "```python\n",
    "{\"page\": {\"$between\": [10,20]}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a40601",
   "metadata": {},
   "source": [
    "### Create Instance\n",
    "\n",
    "First, we create an instance of the PGVector helper class to use its CRUD functionalities.\n",
    "\n",
    "This class is initialized with the **PGVector Python SDK client instance** and the **embedding model instance** , both of which were defined in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dccab807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pgvector import PGVectorDocumentManager\n",
    "\n",
    "crud_manager = PGVectorDocumentManager(\n",
    "    client=client, embedding=embedding, collection_name=\"tutorial_collection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c0c67f",
   "metadata": {},
   "source": [
    "Now you can use the following **CRUD** operations with the ```crud_manager``` instance.\n",
    "\n",
    "These instance allow you to easily manage documents in your ```PGVector```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c53c5",
   "metadata": {},
   "source": [
    "### Upsert Document\n",
    "\n",
    "**Update** existing documents or **insert** if they donâ€™t exist\n",
    "\n",
    "**âœ… Args**\n",
    "\n",
    "- ```texts``` : Iterable[str] â€“ List of text contents to be inserted/updated.\n",
    "\n",
    "- ```metadatas``` : Optional[List[Dict]] â€“ List of metadata dictionaries for each text (optional).\n",
    "\n",
    "- ```ids``` : Optional[List[str]] â€“ Custom IDs for the documents. If not provided, IDs will be auto-generated.\n",
    "\n",
    "- ```**kwargs``` : Extra arguments for the underlying vector store.\n",
    "\n",
    "**ðŸ”„ Return**\n",
    "\n",
    "- ```ids``` : IDs of the upserted documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3a6c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "ids = [str(uuid4()) for _ in docs]\n",
    "\n",
    "\n",
    "args = {\n",
    "    \"texts\": [doc.page_content for doc in docs[:2]],\n",
    "    \"metadatas\": [doc.metadata for doc in docs[:2]],\n",
    "    \"ids\": ids[:2],\n",
    "}\n",
    "\n",
    "\n",
    "upsert_result = crud_manager.upsert(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278fe1ed",
   "metadata": {},
   "source": [
    "### Upsert Parallel\n",
    "\n",
    "Perform **upserts** in **parallel** for large-scale data\n",
    "\n",
    "**âœ… Args**\n",
    "\n",
    "- ```texts``` : Iterable[str] â€“ List of text contents to be inserted/updated.\n",
    "\n",
    "- ```metadatas``` : Optional[List[Dict]] â€“ List of metadata dictionaries for each text (optional).\n",
    "\n",
    "- ```ids``` : Optional[List[str]] â€“ Custom IDs for the documents. If not provided, IDs will be auto-generated.\n",
    "\n",
    "- ```batch_size``` : int â€“ Number of documents per batch (default: 32).\n",
    "\n",
    "- ```workers``` : int â€“ Number of parallel workers (default: 10).\n",
    "\n",
    "- ```**kwargs``` : Extra arguments for the underlying vector store.\n",
    "\n",
    "**ðŸ”„ Return**\n",
    "\n",
    "- ```ids``` : IDs of the upserted documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a89dd8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"texts\": [doc.page_content for doc in docs],\n",
    "    \"metadatas\": [doc.metadata for doc in docs],\n",
    "    \"ids\": ids,\n",
    "    \"batch_size\": 32,\n",
    "    \"max_workers\": 8,\n",
    "}\n",
    "\n",
    "upsert_parallel_result = crud_manager.upsert_parallel(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beea197",
   "metadata": {},
   "source": [
    "### Similarity Search\n",
    "\n",
    "Search for **similar documents** based on **embeddings** .\n",
    "\n",
    "This method uses **\"cosine similarity\"** .\n",
    "\n",
    "\n",
    "**âœ… Args**\n",
    "\n",
    "- ```query``` : str â€“ The text query for similarity search.\n",
    "\n",
    "- ```k``` : int â€“ Number of top results to return (default: 10).\n",
    "\n",
    "```**kwargs``` : Additional search options (e.g., filters).\n",
    "\n",
    "**ðŸ”„ Return**\n",
    "\n",
    "- ```results``` : List[Document] â€“ A list of LangChain Document objects ranked by similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5859782b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1\n",
      "Contents : And he went back to meet the fox. \n",
      "\"Goodbye,\" he said. \n",
      "\"Goodbye,\" said the fox. \"And now here is my secret, a very simple secret: It is only with the heart that one can see rightly; what is essential is invisible to the eye.\" \n",
      "\"What is essential is invisible to the eye,\" the little prince repeated, so that he would be sure to remember.\n",
      "\"It is the time you have wasted for your rose that makes your rose so important.\"\n",
      "Metadata: {'title': 'Chapter 21'}\n",
      "Similarity Score: 0.5081315211410451\n",
      "\n",
      "Rank 2\n",
      "Contents : \"Yes,\" I said to the little prince. \"The house, the stars, the desert-- what gives them their beauty is something that is invisible!\" \n",
      "\"I am glad,\" he said, \"that you agree with my fox.\"\n",
      "Metadata: {'title': 'Chapter 24'}\n",
      "Similarity Score: 0.49512916658197925\n",
      "\n",
      "Rank 3\n",
      "Contents : \"The men where you live,\" said the little prince, \"raise five thousand roses in the same garden-- and they do not find in it what they are looking for.\" \n",
      "\"They do not find it,\" I replied. \n",
      "\"And yet what they are looking for could be found in one single rose, or in a little water.\" \n",
      "\"Yes, that is true,\" I said. \n",
      "And the little prince added: \n",
      "\"But the eyes are blind. One must look with the heart...\"\n",
      "Metadata: {'title': 'Chapter 25'}\n",
      "Similarity Score: 0.4223734643904644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search by query\n",
    "results = crud_manager.search(query=\"What is essential is invisible to the eye.\", k=3)\n",
    "for idx, result in enumerate(results):\n",
    "    print(f\"Rank {idx+1}\")\n",
    "    print(f\"Contents : {result['content']}\")\n",
    "    print(f\"Metadata: {result['metadata']}\")\n",
    "    print(f\"Similarity Score: {result['score']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2577dd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1\n",
      "Contents : \"The men where you live,\" said the little prince, \"raise five thousand roses in the same garden-- and they do not find in it what they are looking for.\" \n",
      "\"They do not find it,\" I replied. \n",
      "\"And yet what they are looking for could be found in one single rose, or in a little water.\" \n",
      "\"Yes, that is true,\" I said. \n",
      "And the little prince added: \n",
      "\"But the eyes are blind. One must look with the heart...\"\n",
      "Metadata: {'title': 'Chapter 25'}\n",
      "Similarity Score: 0.4223734643904644\n",
      "\n",
      "Rank 2\n",
      "Contents : \"The men where you live,\" said the little prince, \"raise five thousand roses in the same garden-- and they do not find in it what they are looking for.\" \n",
      "\"They do not find it,\" I replied. \n",
      "\"And yet what they are looking for could be found in one single rose, or in a little water.\" \n",
      "\"Yes, that is true,\" I said. \n",
      "And the little prince added: \n",
      "\"But the eyes are blind. One must look with the heart...\"\n",
      "Metadata: {'title': 'Chapter 25'}\n",
      "Similarity Score: 0.4223734643904644\n",
      "\n",
      "Rank 3\n",
      "Contents : \"The men where you live,\" said the little prince, \"raise five thousand roses in the same garden-- and they do not find in it what they are looking for.\" \n",
      "\"They do not find it,\" I replied. \n",
      "\"And yet what they are looking for could be found in one single rose, or in a little water.\" \n",
      "\"Yes, that is true,\" I said. \n",
      "And the little prince added: \n",
      "\"But the eyes are blind. One must look with the heart...\"\n",
      "Metadata: {'title': 'Chapter 25'}\n",
      "Similarity Score: 0.4223734643904644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search by query with filters\n",
    "results = crud_manager.search(\n",
    "    query=\"Which asteroid did the little prince come from?\",\n",
    "    k=3,\n",
    "    filter={\"title\": \"Chapter 4\"},\n",
    ")\n",
    "for idx, doc in enumerate(results):\n",
    "    print(f\"Rank {idx+1}\")\n",
    "    print(f\"Contents : {result['content']}\")\n",
    "    print(f\"Metadata: {result['metadata']}\")\n",
    "    print(f\"Similarity Score: {result['score']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0ed0c",
   "metadata": {},
   "source": [
    "### Delete Document\n",
    "\n",
    "Delete documents based on filter conditions\n",
    "\n",
    "**âœ… Args**\n",
    "\n",
    "- ```ids``` : Optional[List[str]] â€“ List of document IDs to delete. If None, deletion is based on filter.\n",
    "\n",
    "- ```filters``` : Optional[Dict] â€“ Dictionary specifying filter conditions (e.g., metadata match).\n",
    "\n",
    "- ```**kwargs``` : Any additional parameters.\n",
    "\n",
    "**ðŸ”„ Return**\n",
    "\n",
    "- None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e3a2c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete done successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete by ids\n",
    "crud_manager.delete(ids=ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60bcb4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete done successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete by filters\n",
    "crud_manager.delete(filters={\"title\": {\"$eq\": \"chapter 4\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30d42d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete done successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete All\n",
    "crud_manager.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testbed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
