{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25733da0",
   "metadata": {},
   "source": [
    "# Qdrant\n",
    "\n",
    "- Author: [HyeonJong Moon](https://github.com/hj0302), [Pupba](#https://github.com/pupba)\n",
    "- Peer Review: [liniar](https://github.com/namyoungkim), [hellohotkey](https://github.com/hellohotkey), [Sohyeon Yim](https://github.com/sohyunwriter)\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/09-VectorStore/05-Qdrant.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/09-VectorStore/05-Qdrant.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial covers how to use **Qdrant****Qdrant** with **LangChain** .\n",
    "\n",
    "**Qdrant** is a high-performance, open-source vector database that stands out with advanced filtering, payload indexing, and native support for hybrid (vector + keyword) search.\n",
    "\n",
    "This tutorial walks you through using **CRUD** operations with the **Qdrant** **storing** , **updating** , **deleting** documents, and performing **similarity-based retrieval** .\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [What is Qdrant?](#what-is-qdrant?)\n",
    "- [Prepare Data](#Prepare-Data)\n",
    "- [Setting up Qdrant](#Setting-up-Qdrant)\n",
    "- [Document Manager](#document-manager)\n",
    "\n",
    "\n",
    "### References\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fac085",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- ```langchain-opentutorial``` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [```langchain-opentutorial```](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98da7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800c732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain-core\",\n",
    "        \"python-dotenv\",\n",
    "        \"qdrant-client\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b36bafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"false\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"Qdrant\",\n",
    "        \"QDRANT_API_KEY\": \"\",\n",
    "        \"QDRANT_URL\": \"\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8011a0c7",
   "metadata": {},
   "source": [
    "You can alternatively set API keys such as ```OPENAI_API_KEY``` in a ```.env``` file and load them.\n",
    "\n",
    "[Note] This is not necessary if you've already set the required API keys in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d7e764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6890920d",
   "metadata": {},
   "source": [
    "## What is Qdrant?\n",
    "\n",
    "![qdrant-logo](./assets/05-qdrant-logo.png)\n",
    "\n",
    "Qdrant is an open-source vector database and similarity search engine built in Rust, designed to handle high-dimensional vector data efficiently.\n",
    "\n",
    "It provides a production-ready service with a user-friendly API for storing, searching, and managing vectors along with additional payload data.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- **High Performance** : Built in Rust for speed and reliability, handling billions of vectors with low latency.  \n",
    "\n",
    "- **Advanced Filtering** : Supports complex filtering with JSON payloads, enabling precise searches based on metadata.  \n",
    "\n",
    "- **Hybrid Search** : Combines vector similarity with keyword-based filtering for enhanced search capabilities.  \n",
    "\n",
    "- **Scalable Deployment** : Offers cloud-native scalability with options for on-premise, cloud, and hybrid deployments.  \n",
    "\n",
    "- **Multi-language Support** : Provides client libraries for Python, JavaScript/TypeScript, Go, and more.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3b5bd2",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "This section guides you through the **data preparation process** .\n",
    "\n",
    "This section includes the following components:\n",
    "\n",
    "- Data Introduction\n",
    "\n",
    "- Preprocess Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508ae7f7",
   "metadata": {},
   "source": [
    "### Data Introduction\n",
    "\n",
    "In this tutorial, we will use the fairy tale **📗 The Little Prince** in PDF format as our data.\n",
    "\n",
    "This material complies with the **Apache 2.0 license** .\n",
    "\n",
    "The data is used in a text (.txt) format converted from the original PDF.\n",
    "\n",
    "You can view the data at the link below.\n",
    "- [Data Link](https://huggingface.co/datasets/sohyunwriter/the_little_prince)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ea4f4",
   "metadata": {},
   "source": [
    "### Preprocess Data\n",
    "\n",
    "In this tutorial section, we will preprocess the text data from The Little Prince and convert it into a list of ```LangChain Document``` objects with metadata. \n",
    "\n",
    "Each document chunk will include a ```title``` field in the metadata, extracted from the first line of each section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4cac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def preprocessing_data(content: str) -> List[Document]:\n",
    "    # 1. Split the text by double newlines to separate sections\n",
    "    blocks = content.split(\"\\n\\n\")\n",
    "\n",
    "    # 2. Initialize the text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,  # Maximum number of characters per chunk\n",
    "        chunk_overlap=50,  # Overlap between chunks to preserve context\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \"],  # Order of priority for splitting\n",
    "    )\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    # 3. Loop through each section\n",
    "    for block in blocks:\n",
    "        lines = block.strip().splitlines()\n",
    "        if not lines:\n",
    "            continue\n",
    "\n",
    "        # Extract title from the first line using square brackets [ ]\n",
    "        first_line = lines[0]\n",
    "        title_match = re.search(r\"\\[(.*?)\\]\", first_line)\n",
    "        title = title_match.group(1).strip() if title_match else \"\"\n",
    "\n",
    "        # Remove the title line from content\n",
    "        body = \"\\n\".join(lines[1:]).strip()\n",
    "        if not body:\n",
    "            continue\n",
    "\n",
    "        # 4. Chunk the section using the text splitter\n",
    "        chunks = text_splitter.split_text(body)\n",
    "\n",
    "        # 5. Create a LangChain Document for each chunk with the same title metadata\n",
    "        for chunk in chunks:\n",
    "            documents.append(Document(page_content=chunk, metadata={\"title\": title}))\n",
    "\n",
    "    print(f\"Generated {len(documents)} chunked documents.\")\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d091a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 262 chunked documents.\n"
     ]
    }
   ],
   "source": [
    "# Load the entire text file\n",
    "with open(\"./data/the_little_prince.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Preprocess Data\n",
    "docs = preprocessing_data(content=content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1977d4ff",
   "metadata": {},
   "source": [
    "## Setting up Qdrant\n",
    "\n",
    "This part walks you through the initial setup of **Qdrant** .\n",
    "\n",
    "This section includes the following components:\n",
    "\n",
    "- Load Embedding Model\n",
    "\n",
    "- Load Qdrant Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eee56b2",
   "metadata": {},
   "source": [
    "### Load Embedding Model\n",
    "\n",
    "In this section, you'll learn how to load an embedding model.\n",
    "\n",
    "This tutorial uses **OpenAI's** **API-Key** for loading the model.\n",
    "\n",
    "*💡 If you prefer to use another embedding model, see the instructions below.*\n",
    "- [Embedding Models](https://python.langchain.com/docs/integrations/text_embedding/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bd5c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\", dimensions=1536)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f65795",
   "metadata": {},
   "source": [
    "### Load Qdrant Client\n",
    "\n",
    "In this section, we'll show you how to load the **database client object** using the **Python SDK** for **Qdrant** .\n",
    "- [Python SDK Docs](https://python-client.qdrant.tech/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eed0ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Database Client Object Function\n",
    "from qdrant_client import QdrantClient\n",
    "import os\n",
    "\n",
    "\n",
    "def get_db_client():\n",
    "    \"\"\"\n",
    "    Initializes and returns a VectorStore client instance.\n",
    "\n",
    "    This function loads configuration (e.g., API key, host) from environment\n",
    "    variables or default values and creates a client object to interact\n",
    "    with the Qdrant Python SDK.\n",
    "\n",
    "    Returns:\n",
    "        client:ClientType - An instance of the Qdrant client.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If required configuration is missing.\n",
    "    \"\"\"\n",
    "\n",
    "    # In this tutorial, use Qdrant Cloud.\n",
    "    # Get your personal Qdrant Cloud URL and API_Key on the official website.\n",
    "    # https://qdrant.tech/documentation/cloud-intro/\n",
    "    # If you want to use on-premise, please refer to -> https://qdrant.tech/documentation/quickstart/\n",
    "\n",
    "    host = os.environ.get(\"QDRANT_URL\", None)\n",
    "    api_key = os.environ.get(\"QDRANT_API_KEY\", None)\n",
    "    try:\n",
    "        client = QdrantClient(url=host, api_key=api_key, timeout=30)\n",
    "    except Exception as e:\n",
    "        print(\"Error\")\n",
    "        print(f\"{e}\")\n",
    "        return None\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b5f4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get DB Client Object\n",
    "client = get_db_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a97a0",
   "metadata": {},
   "source": [
    "## Document Manager\n",
    "\n",
    "For the **LangChain-OpenTutorial**, we have implemented a custom set of **CRUD** functionalities for VectorDBs\n",
    "\n",
    "The following operations are included:\n",
    "\n",
    "- ```upsert``` : Update existing documents or insert if they don’t exist\n",
    "\n",
    "- ```upsert_parallel``` : Perform upserts in parallel for large-scale data\n",
    "\n",
    "- ```similarity_search``` : Search for similar documents based on embeddings\n",
    "\n",
    "- ```delete``` : Remove documents based on filter conditions\n",
    "\n",
    "Each of these features is implemented as class methods specific to each VectorDB.\n",
    "\n",
    "In this tutorial, you'll learn how to use these methods to interact with your VectorDB.\n",
    "\n",
    "*We plan to continuously expand the functionality by adding more common operations in the future.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a40601",
   "metadata": {},
   "source": [
    "### Create Instance\n",
    "\n",
    "First, create an instance of the **Qdrant** helper class to use its CRUD functionalities.\n",
    "\n",
    "This class is initialized with the **Qdrant Python SDK client instance** and the **embedding model instance** , both of which were defined in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dccab807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.qdrant import QdrantDocumentManager\n",
    "\n",
    "# ❗ Qdrant vectorizes using the embedding function. Transfer the \"Embedding Function\" as a parameter.\n",
    "crud_manager = QdrantDocumentManager(client=client, embedding=embedding.embed_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c0c67f",
   "metadata": {},
   "source": [
    "Now you can use the following **CRUD** operations with the ```crud_manager``` instance.\n",
    "\n",
    "These instance allow you to easily manage documents in your **Qdrant** ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c53c5",
   "metadata": {},
   "source": [
    "### Upsert Document\n",
    "\n",
    "**Update** existing documents or **insert** if they don’t exist\n",
    "\n",
    "**✅ Args**\n",
    "\n",
    "- ```texts``` : Iterable[str] – List of text contents to be inserted/updated.\n",
    "\n",
    "- ```metadatas``` : Optional[List[Dict]] – List of metadata dictionaries for each text (optional).\n",
    "\n",
    "- ```ids``` : Optional[List[str]] – Custom IDs for the documents. If not provided, IDs will be auto-generated.\n",
    "\n",
    "- ```**kwargs``` : Extra arguments for the underlying vector store.\n",
    "\n",
    "**🔄 Return**\n",
    "\n",
    "- None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3a6c32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation_id : 70 | Status : completed\n"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "args = {\n",
    "    \"texts\": [doc.page_content for doc in docs[:2]],\n",
    "    \"metadatas\": [doc.metadata for doc in docs[:2]],\n",
    "    \"ids\": [str(uuid4()) for _ in docs[:2]],\n",
    "    \"result_view\": True,\n",
    "    # Add additional parameters if you need\n",
    "}\n",
    "\n",
    "crud_manager.upsert(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278fe1ed",
   "metadata": {},
   "source": [
    "### Upsert Parallel\n",
    "\n",
    "Perform **upsert** in **parallel** for large-scale data\n",
    "\n",
    "**✅ Args**\n",
    "\n",
    "- ```texts``` : Iterable[str] – List of text contents to be inserted/updated.\n",
    "\n",
    "- ```metadatas``` : Optional[List[Dict]] – List of metadata dictionaries for each text (optional).\n",
    "\n",
    "- ```ids``` : Optional[List[str]] – Custom IDs for the documents. If not provided, IDs will be auto-generated.\n",
    "\n",
    "- ```batch_size``` : int – Number of documents per batch (default: 32).\n",
    "\n",
    "- ```workers``` : int – Number of parallel workers (default: 10).\n",
    "\n",
    "- ```**kwargs``` : Extra arguments for the underlying vector store.\n",
    "\n",
    "**🔄 Return**\n",
    "\n",
    "- None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a89dd8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "args = {\n",
    "    \"texts\": [doc.page_content for doc in docs],\n",
    "    \"metadatas\": [doc.metadata for doc in docs],\n",
    "    \"ids\": [str(uuid4()) for _ in docs],\n",
    "    # Add additional parameters if you need\n",
    "}\n",
    "\n",
    "crud_manager.upsert_parallel(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beea197",
   "metadata": {},
   "source": [
    "### Similarity Search\n",
    "\n",
    "Search for **similar documents** based on **embeddings** .\n",
    "\n",
    "This method uses **\"cosine similarity\"** .\n",
    "\n",
    "\n",
    "**✅ Args**\n",
    "\n",
    "- ```query``` : str – The text query for similarity search.\n",
    "\n",
    "- ```k``` : int – Number of top results to return (default: 10).\n",
    "\n",
    "- ```**kwargs``` : Additional search options (e.g., filters).\n",
    "\n",
    "**🔄 Return**\n",
    "\n",
    "- ```results``` : List[Document] – A list of LangChain Document objects ranked by similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5859782b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 | Title : TO LEON WERTH\n",
      "Contents : TO LEON WERTH WHEN HE WAS A LITTLE BOY\n",
      "\n",
      "Rank 1 | Title : Chapter 21\n",
      "Contents : you see the grain-fields down yonder? I do not ea t bread. Wheat is of no use to me. The wheat fields have nothing to say to me. And that is sad. But you have hair that is the colour of gold. Think how wonderful that will be when you have tamed me! The grain, which is also golden, will bring me bac k the thought of you. And I shall love to listen to the wind in the wheat...\"\n",
      "\n",
      "Rank 2 | Title : Chapter 27\n",
      "Contents : Look up at the sky. Ask yourselves: is it yes or no? Has the sheep eaten the flower? And you will see how everything changes... \n",
      "And no grown-up will ever understand that this is a matter of so much importance! \n",
      "(picture)\n",
      "This is, to me, the loveliest and saddest landscape in the world. It is the same as that on the preceding page, but I have drawn it again to impress it on your memory. It is here that the little prince appeared on Earth, and disappeared.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search by query\n",
    "results = crud_manager.search(query=\"What is essential is invisible to the eye.\", k=3)\n",
    "for idx, doc in enumerate(results):\n",
    "    print(f\"Rank {idx} | Title : {doc.metadata['title']}\")\n",
    "    print(f\"Contents : {doc.page_content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "529d8483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 | Title : Chapter 4\n",
      "Contents : But that did not really surprise me much. I knew very well that in addition to the great planets-- such as the Earth, Jupiter, Mars, Venus-- to which we have given names, there are also hundreds of others, some of which are so small that one has a hard time seeing them through the telescope. When an astronomer discovers one of these he does not give it a name, but only a number. He might call it, for example, \"Asteroid 325.\"\n",
      "\n",
      "Rank 1 | Title : Chapter 4\n",
      "Contents : - the narrator speculates as to which asteroid from which the little prince came　　\n",
      "I had thus learned a second fact of great importance: this was that the planet the little prince came from was scarcely any larger than a house!\n",
      "\n",
      "Rank 2 | Title : Chapter 4\n",
      "Contents : weigh? How much money does his father make?\" Only from these figures do they think they have learned anything about him.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search by query with filters\n",
    "results = crud_manager.search(\n",
    "    query=\"Which asteroid did the little prince come from?\",\n",
    "    k=3,\n",
    "    filters=[{\"title\": \"Chapter 4\"}],\n",
    ")\n",
    "for idx, doc in enumerate(results):\n",
    "    print(f\"Rank {idx} | Title : {doc.metadata['title']}\")\n",
    "    print(f\"Contents : {doc.page_content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f140c0e2",
   "metadata": {},
   "source": [
    "### as_retriever\n",
    "\n",
    "The ```as_retriever()``` method creates a LangChain-compatible retriever wrapper.\n",
    "\n",
    "This function allows a ```DocumentManager``` class to return a retriever object by wrapping the internal ```search()``` method, while staying lightweight and independent from full LangChain ```VectorStore``` dependencies.\n",
    "\n",
    "The retriever obtained through this function is compatible with existing LangChain retrievers and can be used in LangChain Pipelines (e.g., RetrievalQA, ConversationalRetrievalChain, Tool, etc.)\n",
    "\n",
    "**✅ Args**\n",
    "\n",
    "- ```search_fn``` : Callable - The function used to retrieve relevant documents. Typically this is ```self.search``` from a ```DocumentManager``` instance.\n",
    "\n",
    "- ```search_kwargs``` : Optional[Dict] - A dictionary of keyword arguments passed to ```search_fn```, such as ```k``` for top-K results or metadata filters.\n",
    "\n",
    "**🔄 Return**\n",
    "\n",
    "- ```LightCustomRetriever``` :BaseRetriever - A lightweight LangChain-compatible retriever that internally uses the given ```search_fn``` and ```search_kwargs```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86de7842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search without filters\n",
    "ret = crud_manager.as_retriever(\n",
    "    search_fn=crud_manager.search, search_kwargs={\"k\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7142d29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'TO LEON WERTH', 'score': 0.2232914, 'id': 'cfa0c496-ab0b-4a31-8f13-90f97ed713da'}, page_content='TO LEON WERTH WHEN HE WAS A LITTLE BOY')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret.invoke(\"Which asteroid did the little prince come from?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfc88ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search with filters\n",
    "ret = crud_manager.as_retriever(\n",
    "    search_fn=crud_manager.search,\n",
    "    search_kwargs={\n",
    "        \"k\": 2,\n",
    "        \"where\": {\"title\": \"Chapter 4\"}  # Filter to only search in Chapter 4\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "943ea257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 2: Search with title filter (Chapter 4)\n",
      "[Document(metadata={'title': 'TO LEON WERTH', 'score': 0.2232914, 'id': 'cfa0c496-ab0b-4a31-8f13-90f97ed713da'}, page_content='TO LEON WERTH WHEN HE WAS A LITTLE BOY'), Document(metadata={'title': 'Chapter 21', 'score': 0.17259452, 'id': 'b72da2e6-8793-4344-b864-7b833b615ea4'}, page_content='you see the grain-fields down yonder? I do not ea t bread. Wheat is of no use to me. The wheat fields have nothing to say to me. And that is sad. But you have hair that is the colour of gold. Think how wonderful that will be when you have tamed me! The grain, which is also golden, will bring me bac k the thought of you. And I shall love to listen to the wind in the wheat...\"')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 2: Search with title filter (Chapter 4)\")\n",
    "print(ret.invoke(\"Which asteroid did the little prince come from?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0ed0c",
   "metadata": {},
   "source": [
    "### Delete Document\n",
    "\n",
    "Delete documents based on filter conditions\n",
    "\n",
    "**✅ Args**\n",
    "\n",
    "- ```ids``` : Optional[List[str]] – List of document IDs to delete. If None, deletion is based on filter.\n",
    "\n",
    "- ```filters``` : Optional[Dict] – Dictionary specifying filter conditions (e.g., metadata match).\n",
    "\n",
    "- ```**kwargs``` : Any additional parameters.\n",
    "\n",
    "**🔄 Return**\n",
    "\n",
    "- None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e3a2c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 data delete...\n"
     ]
    }
   ],
   "source": [
    "# Delete by ids\n",
    "ids = args[\"ids\"][:3]  # The 'ids' value you want to delete\n",
    "crud_manager.delete(ids=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60bcb4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 data delete...\n",
      "Delete All Finished\n"
     ]
    }
   ],
   "source": [
    "# Delete by ids with filters\n",
    "ids = args[\"ids\"][3:]  # The `ids` value corresponding to chapter 6\n",
    "crud_manager.delete(ids=ids, filters=[{\"title\": \"Chapter 6\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30d42d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 data delete...\n",
      "1 data delete...\n",
      "Delete All Finished\n"
     ]
    }
   ],
   "source": [
    "# Delete All\n",
    "crud_manager.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-B290FrwJ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
